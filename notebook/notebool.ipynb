{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 640, 3)\n",
      "(640, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "\n",
    "img1 = cv2.imread(\"../static_files/test_image.jpg\")\n",
    "print(img1.shape)\n",
    "\n",
    "img2 = Image.open(\"../static_files/test_image.jpg\")  \n",
    "img2 = np.asarray(img2)\n",
    "img2 = cv2.cvtColor(img2, cv2.COLOR_RGB2BGR)\n",
    "print(img2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/archive/master.zip\" to /home/caveman/.cache/torch/hub/master.zip\n",
      "YOLOv5 ðŸš€ 2022-12-15 Python-3.10.6 torch-1.11.0+cu102 CPU\n",
      "\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1    229245  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "YOLOv5s summary: 214 layers, 7235389 parameters, 7235389 gradients\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=False, force_reload=True, autoshape=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, '.yolov5s_v2.pt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('.yolov5s_v2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classes = [3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YOLOv5 <class 'models.common.Detections'> instance\n",
       "image 1/1: 640x640 4 motorcycles\n",
       "Speed: 6.5ms pre-process, 379.6ms inference, 3.3ms NMS per image at shape (1, 3, 640, 640)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./model_weight/yolov5l-p_v2.onnx\n"
     ]
    },
    {
     "ename": "DecodeError",
     "evalue": "Error parsing message with type 'onnx.ModelProto'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDecodeError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/caveman/Documents/python_dev/object_tracking_yolov5_deepsort/notebook/notebool.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/caveman/Documents/python_dev/object_tracking_yolov5_deepsort/notebook/notebool.ipynb#W6sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m stub \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/caveman/Documents/python_dev/object_tracking_yolov5_deepsort/notebook/notebool.ipynb#W6sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myolov5-l\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m\"\u001b[39m\u001b[39mzoo:cv/detection/yolov5-l/pytorch/ultralytics/coco/pruned_quant-aggressive_95\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/caveman/Documents/python_dev/object_tracking_yolov5_deepsort/notebook/notebool.ipynb#W6sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myolov5-s\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m\"\u001b[39m\u001b[39mzoo:cv/detection/yolov5-s/pytorch/ultralytics/coco/pruned_quant-aggressive_94\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/caveman/Documents/python_dev/object_tracking_yolov5_deepsort/notebook/notebool.ipynb#W6sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/caveman/Documents/python_dev/object_tracking_yolov5_deepsort/notebook/notebool.ipynb#W6sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m         }\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/caveman/Documents/python_dev/object_tracking_yolov5_deepsort/notebook/notebool.ipynb#W6sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mprint\u001b[39m(model_weight_path)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/caveman/Documents/python_dev/object_tracking_yolov5_deepsort/notebook/notebool.ipynb#W6sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m yolo_pipeline \u001b[39m=\u001b[39m Pipeline\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/caveman/Documents/python_dev/object_tracking_yolov5_deepsort/notebook/notebool.ipynb#W6sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m task\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39myolo\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/caveman/Documents/python_dev/object_tracking_yolov5_deepsort/notebook/notebool.ipynb#W6sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m model_path\u001b[39m=\u001b[39;49m stub\u001b[39m.\u001b[39;49mget(model_size, \u001b[39mNone\u001b[39;49;00m) \u001b[39mif\u001b[39;49;00m pretrained_model \u001b[39melse\u001b[39;49;00m model_weight_path,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/caveman/Documents/python_dev/object_tracking_yolov5_deepsort/notebook/notebool.ipynb#W6sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m class_names\u001b[39m=\u001b[39;49m\u001b[39mlist\u001b[39;49m(key_to_string\u001b[39m.\u001b[39;49mkeys()),   \u001b[39m# if using custom model, pass in a list of classes the model will clasify or a path to a json file containing them\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/caveman/Documents/python_dev/object_tracking_yolov5_deepsort/notebook/notebool.ipynb#W6sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m model_config\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,  \u001b[39m# if using custom model, pass in the path to a local model config file here\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/caveman/Documents/python_dev/object_tracking_yolov5_deepsort/notebook/notebool.ipynb#W6sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/object_tracking_yolov5_deepsort-RND3WqFJ/lib/python3.10/site-packages/deepsparse/pipeline.py:437\u001b[0m, in \u001b[0;36mPipeline.create\u001b[0;34m(task, model_path, engine_type, batch_size, num_cores, scheduler, input_shapes, alias, context, **kwargs)\u001b[0m\n\u001b[1;32m    426\u001b[0m     buckets \u001b[39m=\u001b[39m pipeline_constructor\u001b[39m.\u001b[39mcreate_pipeline_buckets(\n\u001b[1;32m    427\u001b[0m         task\u001b[39m=\u001b[39mtask,\n\u001b[1;32m    428\u001b[0m         model_path\u001b[39m=\u001b[39mmodel_path,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    434\u001b[0m     )\n\u001b[1;32m    435\u001b[0m     \u001b[39mreturn\u001b[39;00m BucketingPipeline(pipelines\u001b[39m=\u001b[39mbuckets)\n\u001b[0;32m--> 437\u001b[0m \u001b[39mreturn\u001b[39;00m pipeline_constructor(\n\u001b[1;32m    438\u001b[0m     model_path\u001b[39m=\u001b[39;49mmodel_path,\n\u001b[1;32m    439\u001b[0m     engine_type\u001b[39m=\u001b[39;49mengine_type,\n\u001b[1;32m    440\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    441\u001b[0m     num_cores\u001b[39m=\u001b[39;49mnum_cores,\n\u001b[1;32m    442\u001b[0m     scheduler\u001b[39m=\u001b[39;49mscheduler,\n\u001b[1;32m    443\u001b[0m     input_shapes\u001b[39m=\u001b[39;49minput_shapes,\n\u001b[1;32m    444\u001b[0m     alias\u001b[39m=\u001b[39;49malias,\n\u001b[1;32m    445\u001b[0m     context\u001b[39m=\u001b[39;49mcontext,\n\u001b[1;32m    446\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    447\u001b[0m )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/object_tracking_yolov5_deepsort-RND3WqFJ/lib/python3.10/site-packages/deepsparse/yolo/pipelines.py:87\u001b[0m, in \u001b[0;36mYOLOPipeline.__init__\u001b[0;34m(self, class_names, model_config, image_size, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_image_size \u001b[39m=\u001b[39m image_size\n\u001b[1;32m     85\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_onnx_temp_file \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m  \u001b[39m# placeholder for potential tmpfile reference\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m     88\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m     89\u001b[0m )\n\u001b[1;32m     91\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(class_names, \u001b[39mstr\u001b[39m):\n\u001b[1;32m     92\u001b[0m     \u001b[39mif\u001b[39;00m class_names\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.json\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/object_tracking_yolov5_deepsort-RND3WqFJ/lib/python3.10/site-packages/deepsparse/pipeline.py:175\u001b[0m, in \u001b[0;36mPipeline.__init__\u001b[0;34m(self, model_path, engine_type, batch_size, num_cores, scheduler, input_shapes, alias, context, executor)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[39mif\u001b[39;00m engine_type\u001b[39m.\u001b[39mlower() \u001b[39m==\u001b[39m DEEPSPARSE_ENGINE:\n\u001b[1;32m    173\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine_args[\u001b[39m\"\u001b[39m\u001b[39mscheduler\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m scheduler\n\u001b[0;32m--> 175\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39monnx_file_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msetup_onnx_file_path()\n\u001b[1;32m    176\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initialize_engine()\n\u001b[1;32m    178\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_size \u001b[39mor\u001b[39;00m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/object_tracking_yolov5_deepsort-RND3WqFJ/lib/python3.10/site-packages/deepsparse/yolo/pipelines.py:160\u001b[0m, in \u001b[0;36mYOLOPipeline.setup_onnx_file_path\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m model_path \u001b[39m=\u001b[39m model_to_path(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_path)\n\u001b[1;32m    159\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_image_size \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_image_size \u001b[39m=\u001b[39m get_onnx_expected_image_shape(onnx\u001b[39m.\u001b[39;49mload(model_path))\n\u001b[1;32m    161\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[39m# override model input shape to given image size\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_image_size, \u001b[39mint\u001b[39m):\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/object_tracking_yolov5_deepsort-RND3WqFJ/lib/python3.10/site-packages/onnx/__init__.py:116\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(f, format, load_external_data)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[39mLoads a serialized ModelProto into memory\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[39mload_external_data is true if the external data under the same directory of the model and load the external data\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39m    Loaded in-memory ModelProto\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m    115\u001b[0m s \u001b[39m=\u001b[39m _load_bytes(f)\n\u001b[0;32m--> 116\u001b[0m model \u001b[39m=\u001b[39m load_model_from_string(s, \u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mformat\u001b[39;49m)\n\u001b[1;32m    118\u001b[0m \u001b[39mif\u001b[39;00m load_external_data:\n\u001b[1;32m    119\u001b[0m     model_filepath \u001b[39m=\u001b[39m _get_file_path(f)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/object_tracking_yolov5_deepsort-RND3WqFJ/lib/python3.10/site-packages/onnx/__init__.py:153\u001b[0m, in \u001b[0;36mload_model_from_string\u001b[0;34m(s, format)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_model_from_string\u001b[39m(s: \u001b[39mbytes\u001b[39m, \u001b[39mformat\u001b[39m: Optional[Any] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ModelProto:\n\u001b[1;32m    143\u001b[0m     \u001b[39m'''\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[39m    Loads a binary string (bytes) that contains serialized ModelProto\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39m        Loaded in-memory ModelProto\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[39mreturn\u001b[39;00m _deserialize(s, ModelProto())\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/object_tracking_yolov5_deepsort-RND3WqFJ/lib/python3.10/site-packages/onnx/__init__.py:94\u001b[0m, in \u001b[0;36m_deserialize\u001b[0;34m(s, proto)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mhasattr\u001b[39m(proto, \u001b[39m'\u001b[39m\u001b[39mParseFromString\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m callable(proto\u001b[39m.\u001b[39mParseFromString)):\n\u001b[1;32m     91\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mNo ParseFromString method is detected. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     92\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mtype is \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(proto)))\n\u001b[0;32m---> 94\u001b[0m decoded \u001b[39m=\u001b[39m cast(Optional[\u001b[39mint\u001b[39m], proto\u001b[39m.\u001b[39;49mParseFromString(s))\n\u001b[1;32m     95\u001b[0m \u001b[39mif\u001b[39;00m decoded \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m decoded \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(s):\n\u001b[1;32m     96\u001b[0m     \u001b[39mraise\u001b[39;00m google\u001b[39m.\u001b[39mprotobuf\u001b[39m.\u001b[39mmessage\u001b[39m.\u001b[39mDecodeError(\n\u001b[1;32m     97\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mProtobuf decoding consumed too few bytes: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m out of \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     98\u001b[0m             decoded, \u001b[39mlen\u001b[39m(s)))\n",
      "\u001b[0;31mDecodeError\u001b[0m: Error parsing message with type 'onnx.ModelProto'"
     ]
    }
   ],
   "source": [
    "from deepsparse.pipelines.custom_pipeline import CustomTaskPipeline\n",
    "from deepsparse import Pipeline\n",
    "import json,os\n",
    "\n",
    "static_file_path= '../static_files/yolo_classes.json'\n",
    "try:\n",
    "    with open(static_file_path, 'r') as fp:\n",
    "        key_to_string = json.load(fp)\n",
    "    string_to_key = {value:key for key, value in key_to_string.items()}\n",
    "except Exception as e:\n",
    "    raise Exception(f\"Error {e} while loading model class\")\n",
    "\n",
    "kwargs = {}\n",
    "# ***************************** initialize YOLO-V5 **********************************\n",
    "# self.detector = torch.load(kwargs.get('weights','yolov5/weights/yolov5s.pt'), map_location=self.device)['model'].float()  # load to FP32\n",
    "model_size = kwargs.get('model_size','yolov5l-p') #['yolov5-s', 'yolov5-l']\n",
    "model_weight_path = kwargs.get('model_weight_path', \"./model_weight/\"+model_size+\"_v2.onnx\") #'yolov5/weights/yolov5s.pt') \"./model_weight/yolov5s.pt\"\n",
    "pretrained_model = False if os.path.exists(model_weight_path) else True\n",
    "stub = {\n",
    "            \"yolov5-l\":\"zoo:cv/detection/yolov5-l/pytorch/ultralytics/coco/pruned_quant-aggressive_95\",\n",
    "            \"yolov5-s\":\"zoo:cv/detection/yolov5-s/pytorch/ultralytics/coco/pruned_quant-aggressive_94\",\n",
    "            'yolov5l-p':\"zoo:cv/detection/yolov5-l/pytorch/ultralytics/coco/pruned-aggressive_98\",\n",
    "            'yolov5l-pq':\"zoo:cv/detection/yolov5-l/pytorch/ultralytics/coco/pruned_quant-aggressive_95\",\n",
    "\n",
    "        }\n",
    "print(model_weight_path)\n",
    "yolo_pipeline = Pipeline.create(\n",
    "task=\"yolo\",\n",
    "model_path= stub.get(model_size, None) if pretrained_model else model_weight_path,\n",
    "class_names=list(key_to_string.keys()),   # if using custom model, pass in a list of classes the model will clasify or a path to a json file containing them\n",
    "model_config=None,  # if using custom model, pass in the path to a local model config file here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(\"model_weight\"):\n",
    "    os.makedirs(\"model_weight\")\n",
    "\n",
    "if os.path.isfile(yolo_pipeline.onnx_file_path):\n",
    "    os.rename(yolo_pipeline.onnx_file_path, model_weight_path) if pretrained_model else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./model_weight/yolov5-s_v2.onnx'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yolo_pipeline.onnx_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "3 validation errors for YOLOOutput\nboxes\n  field required (type=value_error.missing)\nscores\n  field required (type=value_error.missing)\nlabels\n  field required (type=value_error.missing)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/home/caveman/Documents/python_dev/object_tracking_yolov5_deepsort/notebook/notebool.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/caveman/Documents/python_dev/object_tracking_yolov5_deepsort/notebook/notebool.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m yolo_pipeline\u001b[39m.\u001b[39;49moutput_schema()\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/object_tracking_yolov5_deepsort-RND3WqFJ/lib/python3.10/site-packages/pydantic/main.py:342\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: 3 validation errors for YOLOOutput\nboxes\n  field required (type=value_error.missing)\nscores\n  field required (type=value_error.missing)\nlabels\n  field required (type=value_error.missing)"
     ]
    }
   ],
   "source": [
    "yolo_pipeline.output_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "image = cv2.imread(\"../static_files/test_image.jpg\")\n",
    "image.astype(np.uint8)\n",
    "print(image.shape)\n",
    "# yolo_pipeline.class_names([2,3])\n",
    "pipeline_outputs = yolo_pipeline(images=image, iou_thres=0.6, conf_thres=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YOLOOutput(boxes=[[[45.29338073730469, 168.49630737304688, 228.07969665527344, 311.3185119628906], [76.69711303710938, 32.82611083984375, 199.724365234375, 131.873291015625], [63.94458770751953, 485.4278564453125, 213.818115234375, 621.5233154296875], [240.37136840820312, 541.4109497070312, 394.8977966308594, 614.7621459960938], [252.99996948242188, 40.96147155761719, 404.4091491699219, 129.52249145507812], [421.9398498535156, 201.61544799804688, 581.795166015625, 300.8406066894531], [430.152099609375, 519.798583984375, 578.988525390625, 620.963623046875], [75.14987182617188, 325.3128662109375, 195.07424926757812, 470.36883544921875], [460.8572082519531, 352.4356689453125, 578.5552978515625, 451.70166015625], [426.97796630859375, 15.077621459960938, 588.6062622070312, 147.41343688964844], [245.1121826171875, 197.54347229003906, 390.9814453125, 287.2884521484375], [242.71847534179688, 342.217529296875, 400.8564147949219, 463.16705322265625]]], scores=[[0.934207558631897, 0.9156649708747864, 0.9097804427146912, 0.90463787317276, 0.8891618251800537, 0.8874203562736511, 0.8869575262069702, 0.8805232048034668, 0.8648037910461426, 0.8235767483711243, 0.7745827436447144, 0.7658988237380981]], labels=[['3', '3', '3', '2', '2', '7', '7', '3', '7', '7', '2', '2']])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "object_tracking_yolov5_deepsort-RND3WqFJ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8477147905689faec5a2518b4111d350571af744bf9bd8a13c4f3a0f2cc376e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
